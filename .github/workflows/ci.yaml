name: ci

on:
  pull_request:
    branches:
      - master
  push:
    branches:
      - master
  release:
    types:
      - created
  merge_group:
    types:
      - checks_requested

permissions:
  contents: read

env:
  ONCO_ANALYTICS_NAMESPACE_NAME: bzkf-onco-analytics

jobs:
  build-analytics-on-fhir-image:
    name: build analytics-on-fhir container image
    uses: miracum/.github/.github/workflows/standard-build.yaml@8d3203b6598feaa0c20f26351cc118bd4a158197 # v1.20.0
    permissions:
      contents: write
      id-token: write
      packages: write
      pull-requests: write
      actions: read
      security-events: write
    with:
      image: ghcr.io/${{ github.repository }}/analytics-on-fhir
      build-context: .
      enable-build-test-layer: false
    secrets:
      github-token: ${{ secrets.GITHUB_TOKEN }}

  test-analytics-on-fhir:
    name: run analytics-on-fhir tests
    runs-on: ubuntu-24.04
    defaults:
      run:
        working-directory: .
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false

      - name: install graphviz
        run: |
          sudo apt install -y graphviz

      - name: Install uv
        uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
        with:
          enable-cache: true
          activate-environment: true
          working-directory: .

      - uses: actions/setup-java@f2beeb24e141e01a676f977032f5a29d81c9e27e # v5.1.0
        with:
          distribution: "temurin"
          java-version-file: ".java-version"

      - name: Install test dependencies
        run: |
          uv sync --locked --all-extras --dev

      - name: Run tests
        run: |
          uv run pytest -vv --log-cli-level=20 --cov=analytics_on_fhir --cov-report=html --capture=no

      - name: Upload test coverage
        if: ${{ always() }}
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: analytics-on-fhir-test-coverage
          path: src/analytics_on_fhir/htmlcov/

  test-compose:
    name: run compose e2e tests
    runs-on: ubuntu-24.04
    needs:
      - build-analytics-on-fhir-image
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@5ef0c079ce82195b2a36a210272d6b661572d83e # v2.14.2
        with:
          egress-policy: audit # change to 'egress-policy: block' after couple of runs

      # <https://docs.docker.com/storage/containerd/>
      # via <https://github.com/docker/setup-buildx-action/issues/257>
      - name: Set up containerd image store
        shell: bash
        run: |
          [ -f /etc/docker/daemon.json ] || echo "{}" | sudo tee /etc/docker/daemon.json
          jq '. | .+{"features": {"containerd-snapshotter": true}}' /etc/docker/daemon.json > /tmp/docker-daemon-with-containerd.json
          sudo mv /tmp/docker-daemon-with-containerd.json /etc/docker/daemon.json
          cat /etc/docker/daemon.json
          sudo systemctl restart docker
          docker info -f '{{ .DriverStatus }}'

      - name: Free disk space
        uses: endersonmenezes/free-disk-space@e6ed9b02e683a3b55ed0252f1ee469ce3b39a885 # v3.1.0
        with:
          remove_android: true
          remove_dotnet: true
          remove_haskell: true
          remove_tool_cache: true
          rm_cmd: "rmz"

      - name: Download image
        if: ${{ github.event_name == 'pull_request' }}
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: ${{ needs.build-analytics-on-fhir-image.outputs.image-slug }}
          path: /tmp

      - name: Load image
        if: ${{ github.event_name == 'pull_request' }}
        run: |
          docker load --input /tmp/image.tar
          docker image ls

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: start Kafka & Kafka Connect
        working-directory: docker-compose/
        run: |
          docker compose -f compose.kafka.yaml up -d
          # ðŸ˜¬
          sleep 60

      - name: load the obds reports from disk, turn them into individual reports and send them to Kafka
        working-directory: docker-compose/
        env:
          DECOMPOSE_XMLS_IMAGE_TAG: ${{ needs.build-analytics-on-fhir-image.outputs.image-version }}
          STUDY_NAME: all
          LOCATION: ci
        run: |
          USER_ID=${UID} GROUP_ID=${GID} docker compose --env-file=.demo.env -f compose.decompose-xmls.yaml up

      - name: convert reports to FHIR resources
        working-directory: docker-compose/
        run: |
          docker compose -f compose.obds-to-fhir.yaml up -d
          # not a great idea, probably better to create an init container
          # exiting if the output topic contains the expected number of resources after some tries.
          sleep 60

      - name: de-identify the resources
        working-directory: docker-compose/
        run: |
          docker compose --env-file=.demo.env -f compose.pseudonymization.yaml up -d
          # again, not a great idea.
          sleep 60

      - name: load the resources into Delta Lake tables
        working-directory: docker-compose/
        run: |
          docker compose --project-name=docker-compose --env-file=.demo.env -f compose.fhir-to-delta.yaml -f trino-pathling/compose.yaml --project-directory trino-pathling/ up -d
          # once again, a bad idea
          sleep 120

      - name: query them using trino
        run: |
          curl -o trino-cli.jar https://repo1.maven.org/maven2/io/trino/trino-cli/472/trino-cli-472-executable.jar
          java -jar trino-cli.jar --debug --execute 'SELECT * FROM fhir.default.Patient'
          java -jar trino-cli.jar --debug --execute 'SELECT * FROM fhir.default.Observation'
          java -jar trino-cli.jar --debug --execute 'SELECT * FROM fhir.default.Condition'

      - name: Run all studies
        working-directory: docker-compose/
        env:
          STUDY_NAME: "all"
          ANALYTICS_ON_FHIR_IMAGE_TAG: ${{ needs.build-analytics-on-fhir-image.outputs.image-version }}
        run: |
          sudo chown -R 65532:65532 ./opal-output/
          docker compose --env-file=.demo.env -f compose.analytics-on-fhir.yaml up

      - name: upload output
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: opal-df
          path: |
            docker-compose/opal-output/

      - name: Print compose logs
        if: always()
        working-directory: docker-compose/
        run: |
          docker compose --env-file=.demo.env \
            -f compose.kafka.yaml \
            -f compose.decompose-xmls.yaml \
            -f compose.obds-to-fhir.yaml \
            -f compose.analytics-on-fhir.yaml \
            -f compose.fhir-to-delta.yaml \
            -f trino-pathling/compose.yaml logs | tee compose-logs.txt

      - name: Upload compose dump
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: compose-logs
          path: |
            docker-compose/compose-logs.txt

  lint:
    uses: miracum/.github/.github/workflows/standard-lint.yaml@4a5ed0cb8f87fe5197b33c2619b3431786e9b6a5 # v1.19.2
    permissions:
      contents: read
      pull-requests: write
      issues: write
      security-events: write
      actions: read
    with:
      enable-validate-gradle-wrapper: false
      codeql-languages: '["python"]'
      enable-codeql: false
      enable-verify-base-image-signature: false
    secrets:
      github-token: ${{ secrets.GITHUB_TOKEN }}

  release:
    if: ${{ startsWith(github.ref, 'refs/tags/') }}
    permissions:
      actions: read
      contents: write
      id-token: write
      packages: write
    needs:
      - build-analytics-on-fhir-image
    uses: ./.github/workflows/release.yaml
