name: ci

on:
  pull_request:
    branches:
      - master
  push:
    branches:
      - master
  release:
    types:
      - created
permissions: read-all

env:
  ONCO_ANALYTICS_NAMESPACE_NAME: bzkf-onco-analytics

jobs:
  build-decompose-xml-image:
    name: build decompose-xmls container image
    uses: miracum/.github/.github/workflows/standard-build.yaml@4cc91eaee2ea6c0513da1195a6b53bb9c16f5666 # v1.13.1
    permissions:
      contents: write
      id-token: write
      packages: write
      pull-requests: write
      actions: read
      security-events: write
    with:
      image: ghcr.io/${{ github.repository }}/decompose-xmls
      build-context: src/decompose_xmls
      enable-build-test-layer: false
    secrets:
      github-token: ${{ secrets.GITHUB_TOKEN }}

  build-obds-fhir-to-opal-image:
    name: build obds-fhir-to-opal container image
    uses: miracum/.github/.github/workflows/standard-build.yaml@4cc91eaee2ea6c0513da1195a6b53bb9c16f5666 # v1.13.1
    permissions:
      contents: write
      id-token: write
      packages: write
      pull-requests: write
      actions: read
      security-events: write
    with:
      image: ghcr.io/${{ github.repository }}/obds-fhir-to-opal
      build-context: src/obds_fhir_to_opal
      enable-build-test-layer: false
    secrets:
      github-token: ${{ secrets.GITHUB_TOKEN }}

  lint:
    uses: miracum/.github/.github/workflows/standard-lint.yaml@4cc91eaee2ea6c0513da1195a6b53bb9c16f5666 # v1.13.1
    permissions:
      contents: read
      pull-requests: write
      issues: write
      security-events: write
      actions: read
    with:
      enable-validate-gradle-wrapper: false
      codeql-languages: '["python"]'
      enable-codeql: false
      enable-verify-base-image-signature: false
    secrets:
      github-token: ${{ secrets.GITHUB_TOKEN }}

  tests:
    strategy:
      matrix:
        # Python versions to run tests for
        python-version: ["3.11"]
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38 # v5.4.0
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          cd src/decompose_xmls
          pip install pytest
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      - name: Run decompose_xmls tests
        run: |
          cd src/decompose_xmls
          pytest

  test-compose:
    runs-on: ubuntu-24.04
    needs:
      - build-decompose-xml-image
      - build-obds-fhir-to-opal-image
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          persist-credentials: false

      - name: start Kafka & Kafka Connect
        working-directory: docker-compose/
        run: |
          docker compose -f compose.kafka.yaml up -d
          # ðŸ˜¬
          sleep 60

      - name: load the obds reports from disk, turn them into individual reports and send them to Kafka
        working-directory: docker-compose/
        run: |
          USER_ID=${UID} GROUP_ID=${GID} docker compose -f compose.decompose-xmls.yaml up

      - name: convert reports to FHIR resources
        working-directory: docker-compose/
        run: |
          docker compose -f compose.obds-to-fhir.yaml up -d
          # not a great idea, probably better to create an init container
          # exiting if the output topic contains the expected number of resources after some tries.
          sleep 60

      - name: de-identify the resources
        working-directory: docker-compose/
        run: |
          docker compose --env-file=.demo.env -f compose.pseudonymization.yaml up -d
          # again, not a great idea.
          sleep 60

      # this currently uses the original, non-de-identified resources!
      - name: convert the FHIR resources to the CSV dataset
        working-directory: docker-compose/
        run: |
          sudo chown -R 1001:1001 ./opal-output/
          docker compose -f compose.obds-fhir-to-opal.yaml up

      - name: upload the CSV
        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0
        with:
          name: opal-df
          path: |
            docker-compose/opal-output/

      - name: load the resources into Delta Lake tables
        working-directory: docker-compose/
        run: |
          docker compose --project-name=docker-compose --env-file=.demo.env -f trino-pathling/compose.yaml up -d
          # once again, a bad idea
          sleep 60

      - name: query them using trino
        run: |
          curl -o trino-cli.jar https://repo1.maven.org/maven2/io/trino/trino-cli/472/trino-cli-472-executable.jar
          java -jar trino-cli.jar --debug --execute 'SELECT * FROM fhir.default.Patient'

      - name: Print compose logs
        if: always()
        working-directory: docker-compose/
        run: |
          docker compose --env-file=.demo.env \
            -f compose.kafka.yaml \
            -f compose.decompose-xmls.yaml \
            -f compose.obds-to-fhir.yaml \
            -f compose.obds-fhir-to-opal.yaml \
            -f trino-pathling/compose.yaml logs | tee compose-logs.txt

      - name: Upload compose dump
        if: always()
        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0
        with:
          name: compose-logs
          path: |
            docker-compose/compose-logs.txt

  test-k8s:
    runs-on: ubuntu-24.04
    # disabled since the major deployment platform is currently
    # docker compose anyways
    if: ${{ false }}
    # run tests only on PRs
    # ${{ github.event_name == 'pull_request' }}
    needs:
      - build-decompose-xml-image
      - build-obds-fhir-to-opal-image
    steps:
      - name: install k3s
        run: |
          curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.28.3+k3s2 sh -

      - name: setup .kube/config
        run: |
          mkdir ~/.kube
          sudo k3s kubectl config view --raw | tee ~/.kube/config > /dev/null
          chmod 600 ~/.kube/config

      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: install dependencies
        run: |
          kubectl get node

          # via <https://stackoverflow.com/a/65411733>
          kubectl create namespace "${ONCO_ANALYTICS_NAMESPACE_NAME}" --dry-run=client -o yaml | kubectl apply -f -
          kubectl config set-context --current --namespace="${ONCO_ANALYTICS_NAMESPACE_NAME}"

          kubectl config view

          helm dependency build charts/prerequisites
          helm upgrade --install --wait --timeout=10m --set strimzi-kafka-operator.generateNetworkPolicy=false onco-analytics-on-fhir-prerequisites charts/prerequisites

          kubectl apply -f k8s/
          kubectl wait kafka/bzkf-dizbox-cluster --for=condition=Ready --timeout=600s

          kubectl apply -f k8s/kafka-bridge.yaml
          kubectl wait kafkabridge/bzkf-dizbox-bridge --for=condition=Ready --timeout=600s

          kubectl get all -A

      - name: install onco-analytics-on-fhir
        run: |
          helm repo add miracum https://miracum.github.io/charts
          helm repo add akhq https://akhq.io/
          helm repo add hapi-fhir-jpaserver-starter https://hapifhir.github.io/hapi-fhir-jpaserver-starter

          helm dependency build charts/onco-analytics-on-fhir
          helm upgrade --install --wait --timeout=10m onco-analytics-on-fhir charts/onco-analytics-on-fhir

          kubectl get all -A

      - name: test deployments
        run: |
          helm test onco-analytics-on-fhir

          kubectl wait deployment/onco-analytics-on-fhir-stream-processors-obds-to-fhir --for=condition=Available --timeout=300s
          kubectl wait deployment/onco-analytics-on-fhir-stream-processors-fhir-to-server --for=condition=Available --timeout=300s

      - name: Print cluster logs
        if: always()
        run: |
          kubectl cluster-info dump -o yaml | tee kind-cluster-dump.txt

      - name: Upload cluster dump
        if: always()
        uses: actions/upload-artifact@65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08 # v4.6.0
        with:
          name: kind-cluster-dump.txt
          path: |
            kind-cluster-dump.txt

  build-air-gapped-installer:
    runs-on: ubuntu-24.04
    if: ${{ github.event_name == 'pull_request' }}
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be # v1.3.1
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - run: |
          ./build-air-gapped-installer.sh

  release:
    if: ${{ startsWith(github.ref, 'refs/tags/') }}
    permissions:
      actions: read
      contents: write
      id-token: write
      packages: write
    needs:
      - build-decompose-xml-image
      - build-obds-fhir-to-opal-image
    uses: ./.github/workflows/release.yaml
